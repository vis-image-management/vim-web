<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="/vim-web/feed.xml" rel="self" type="application/atom+xml" /><link href="/vim-web/" rel="alternate" type="text/html" /><updated>2024-10-23T19:15:32+00:00</updated><id>/vim-web/feed.xml</id><title type="html">visualization and image data management</title><subtitle>VIM (Visualization and Image Data Management) aims to connect research labs, university hospitals, and open source partners. Its mission is to provide a platform for research and educational exchange and to join efforts in developing and standardizing data formats, platforms, and interfaces for analyzing and communicating biomedical imaging data.</subtitle><entry><title type="html">31st Meeting “Visual analytics for high-plex spatial profiling with the MCMICRO analysis pipeline”</title><link href="/vim-web/2024/10/25/meeting-31.html" rel="alternate" type="text/html" title="31st Meeting “Visual analytics for high-plex spatial profiling with the MCMICRO analysis pipeline”" /><published>2024-10-25T00:00:00+00:00</published><updated>2024-10-23T19:13:52+00:00</updated><id>/vim-web/2024/10/25/meeting-31</id><content type="html" xml:base="/vim-web/2024/10/25/meeting-31.html"><![CDATA[<p>Please join us Friday, October 25th at 11 AM ET for the Visualization and Image Data Management meeting. We will be hearing from Jeremy Muhlich about the MCMICRO analysis pipeline.</p>

<p>Spatial ‘omics has emerged as a breakthrough technology for understanding the types and states of cells in the intact environment of tissues and tumors. Subcellular resolution, high-plex tissue immunofluorescence is particularly promising because it builds on two centuries of histopathology and tissue biology, exploits the latest advances in computational microscopy, and links changes in protein levels to changes in morphology. To support standardized high-throughput analysis of this data type, our team developed MCMICRO: a Nextflow pipeline for processing cyclic imaging of large intact tissues to extract single-cell and sub-cellular features as well as whole-slide multi-gigapixel images with as many as 100 channels. I will summarize the current state of MCMICRO, provide our roadmap for future development, and detail a series of proposed enhancements to streamline data access for downstream visualization and visual analytics tools in addition to cloud-based operation.</p>

<p>Presenters: Jeremy Muhlich is Director of Software Engineering at the Laboratory of Systems Pharmacology at Harvard Medical School.</p>]]></content><author><name>Jeremy Muhlich, Director of Software Engineering, Laboratory of Systems Pharmacology, Harvard Medical School</name></author><category term="imaging," /><category term="visual-analytics" /><summary type="html"><![CDATA[Please join us Friday, October 25th at 11 AM ET for the Visualization and Image Data Management meeting. We will be hearing from Jeremy Muhlich about the MCMICRO analysis pipeline.]]></summary></entry><entry><title type="html">30th Meeting “The OME 2024 NGFF Challenge”</title><link href="/vim-web/2024/09/20/meeting-30.html" rel="alternate" type="text/html" title="30th Meeting “The OME 2024 NGFF Challenge”" /><published>2024-09-20T00:00:00+00:00</published><updated>2024-10-23T19:13:52+00:00</updated><id>/vim-web/2024/09/20/meeting-30</id><content type="html" xml:base="/vim-web/2024/09/20/meeting-30.html"><![CDATA[<p>Please join us Friday, September 20th at 11 AM ET for the Visualization and Image Data Management meeting. We will be hearing from Will Moore about the OME 2024 NGFF Challenge.</p>

<p>The OME-NGFF project is an effort by a growing community to develop a bioimaging “next generation file format” suitable for distributed computing at scale. Over the summer of 2024, we have challenged ourselves to push towards migration from Zarr v2 to Zarr v3. We have been updating our process, specifications and software with the goal of generating a large, community-wide collection of sample datasets. This work is a significant step towards the next release of OME-Zarr and will help promote its adoption by the wider bio-imaging community.</p>

<p>Presenters: Will Moore is a software developer at OME and the University of Dundee.</p>]]></content><author><name>Will Moore, Software Developer, OME and University of Dundee.</name></author><category term="visualization," /><category term="tools," /><category term="viewers," /><category term="formats," /><category term="standards," /><category term="imaging," /><category term="training" /><summary type="html"><![CDATA[Please join us Friday, September 20th at 11 AM ET for the Visualization and Image Data Management meeting. We will be hearing from Will Moore about the OME 2024 NGFF Challenge.]]></summary></entry><entry><title type="html">29th Meeting “A Mixed Reality and 2D Display Hybrid Approach for Visual Analysis of 3D Tissue Maps”</title><link href="/vim-web/2024/07/19/meeting-29.html" rel="alternate" type="text/html" title="29th Meeting “A Mixed Reality and 2D Display Hybrid Approach for Visual Analysis of 3D Tissue Maps”" /><published>2024-07-19T00:00:00+00:00</published><updated>2024-10-23T19:13:52+00:00</updated><id>/vim-web/2024/07/19/meeting-29</id><content type="html" xml:base="/vim-web/2024/07/19/meeting-29.html"><![CDATA[<p>Please join us Friday, July 19th at 11 AM ET for the Visualization and Image Data Management meeting. We will be hearing from Eric Mörth about a mixed reality and 2D display hybrid approach for visual analysis of 3D tissue maps.</p>

<p>We present the design and a qualitative evaluation of a novel hybrid system that integrates a Mixed Reality (MR) stereoscopic view of 3D spatial data with linked views on a traditional 2D display. Our system tackles visualization challenges in the rapidly growing field of spatial biology that measures molecular components of tissues in their native spatial context and produces 3D tissue maps with unprecedented complexity and resolution. This field is particularly challenging due to the diversity in techniques in active development that generate 3D maps with vastly different properties. Throughout our process, we collaborated closely with experts in this biological domain to iteratively design, prototype, and ultimately test a hybrid system we used in three in-depth case studies. We extended the web-based Vitessce framework for single-cell analysis, which domain experts already use. We integrated a WebXR spatial view to enable direct access through a web browser. We used the first prototype in a formative user study (n=20 users) at a scientific meeting and obtained informal feedback used to improve the prototype. A qualitative evaluation (n=15 users) of a second prototype revealed that all participants see value in a hybrid system, even among those who self-reported as being skeptical of MR. We share insights from user feedback sessions that strongly support combining direct hand interaction in MR with traditional mouse input on a 2D display.</p>

<p>Presenters: Eric Mörth is a postdoctoral fellow in the HIDIVE Lab at Harvard Medical School.</p>]]></content><author><name>Eric Mörth, Postdoctoral Fellow, HIDIVE Lab, Harvard Medical School</name></author><category term="visualization," /><category term="tools," /><category term="viewers," /><category term="visual-analytics," /><category term="imaging" /><summary type="html"><![CDATA[Please join us Friday, July 19th at 11 AM ET for the Visualization and Image Data Management meeting. We will be hearing from Eric Mörth about a mixed reality and 2D display hybrid approach for visual analysis of 3D tissue maps.]]></summary></entry><entry><title type="html">28th Meeting “psudo, Exploring Multi-Channel Biomedical Image Data with Spatially and Perceptually Optimized Pseudocoloring”</title><link href="/vim-web/2024/06/14/meeting-28.html" rel="alternate" type="text/html" title="28th Meeting “psudo, Exploring Multi-Channel Biomedical Image Data with Spatially and Perceptually Optimized Pseudocoloring”" /><published>2024-06-14T00:00:00+00:00</published><updated>2024-10-23T19:13:52+00:00</updated><id>/vim-web/2024/06/14/meeting-28</id><content type="html" xml:base="/vim-web/2024/06/14/meeting-28.html"><![CDATA[<p>Please join us Friday, June 14th at 11 AM ET for the Visualization and Image Data Management meeting. We will be hearing from Simon Warchol about psudo.</p>

<p>We present psudo, an interactive system that allows users to create optimal color palettes for multichannel spatial data. In psudo, a novel optimization method generates palettes that maximize the perceptual differences between channels while mitigating confusing color blending in overlapping channels. We integrate this method into a system that allows users to explore multi-channel image data and compare and evaluate color palettes for their data. An interactive lensing approach provides on-demand feedback on channel overlap and a color confusion metric while giving context to the underlying channel values. Color palettes can be applied globally or, using the lens, to local regions of interest. We evaluate our approach through a crowdsourced user study and with a case-study with a cancer biologist.</p>

<p>Presenters: Simon is a PhD Candidate in Computer Science at Harvard University, advised by Hanspeter Pfister and co-advised by Peter Sorger. His research focuses on visual analytics and visualization for cancer biology. He is a member of the Visual Computing Group and the Laboratory of Systems Pharmacology.</p>]]></content><author><name>Simon Warchol, PhD Candidate, Visual Computing Group, Harvard University</name></author><category term="visualization," /><category term="tools," /><category term="viewers," /><category term="visual-analytics," /><category term="imaging" /><summary type="html"><![CDATA[Please join us Friday, June 14th at 11 AM ET for the Visualization and Image Data Management meeting. We will be hearing from Simon Warchol about psudo.]]></summary></entry><entry><title type="html">27th Meeting “NCI Imaging Data Commons, May 2024 status update”</title><link href="/vim-web/2024/05/17/meeting-27.html" rel="alternate" type="text/html" title="27th Meeting “NCI Imaging Data Commons, May 2024 status update”" /><published>2024-05-17T00:00:00+00:00</published><updated>2024-10-23T19:13:52+00:00</updated><id>/vim-web/2024/05/17/meeting-27</id><content type="html" xml:base="/vim-web/2024/05/17/meeting-27.html"><![CDATA[<p>Please join us Friday, May 17th at 11 AM ET for the Visualization and Image Data Management meeting. We will be hearing from Andriy Fedorov about the NCI Imaging Data Commons.</p>

<p>NCI Imaging Data Commons (IDC) is a cloud-based environment containing publicly available cancer imaging data co-located with analysis and exploration tools and resources. As of May 2024, IDC offers over 65 TB of cancer imaging data - radiology and microscopy - along with the annotations and analysis results and collection-specific clinical data accompanying the images. All of the data available in IDC is shared via public, free egress cloud buckets, with over 95% of the data shared under a permissive license not restricting commercial reuse. As a data commons, IDC aims to serve not just as a repository of data, but also as an environment for exploration, analysis and sharing. In this presentation I will give some of the highlights of the recent developments, focusing on new datasets available in IDC, new capabilities of the accompanying tools developed by IDC, and new use cases demonstrating the utility of IDC and cloud computing.</p>

<p>Presenters: Andriy Fedorov is Associate Professor of Radiology at Harvard Medical School and the Surgical Planning Laboratory within the Department of Radiology at Brigham and Women’s Hospital.</p>]]></content><author><name>Andriy Fedorov, Associate Professor of Radiology, Harvard Medical School</name></author><category term="imaging," /><category term="tools," /><category term="viewers," /><category term="platforms," /><category term="management" /><summary type="html"><![CDATA[Please join us Friday, May 17th at 11 AM ET for the Visualization and Image Data Management meeting. We will be hearing from Andriy Fedorov about the NCI Imaging Data Commons.]]></summary></entry><entry><title type="html">26th Meeting “Performant Web-Based Interactive Visualization Tool for Spatially-Resolved Transcriptomics Experiments”</title><link href="/vim-web/2024/04/19/meeting-26.html" rel="alternate" type="text/html" title="26th Meeting “Performant Web-Based Interactive Visualization Tool for Spatially-Resolved Transcriptomics Experiments”" /><published>2024-04-19T00:00:00+00:00</published><updated>2024-10-23T19:13:52+00:00</updated><id>/vim-web/2024/04/19/meeting-26</id><content type="html" xml:base="/vim-web/2024/04/19/meeting-26.html"><![CDATA[<p>Please join us Friday, 04/19/2024 11AM ET, for a talk titled “Practical improvements to image sharing workflows in Minerva”. 
A free and open-source tool, Minerva, has long been in use to render static single-page websites that share scientific images with collaborators and the public. New priorities have emerged from a growing number of users: embedding sample-specific metadata, generating similar pages for many samples, and exporting all channels with semi-automated contrast settings. New workflows and processes to address these needs emerged from a collaborative effort led by the data management and informatics teams at the LSP.</p>

<p>Presenters: John Hoffer is a software engineer at the Laboratory of System Pharmacology at Harvard Medical School. His work focuses on image processing, scientific visualization, and web development.</p>]]></content><author><name>John Hoffer, Software Engineer, Laboraratory of Systems Pharmacology, Harvard Medical School</name></author><category term="visualization," /><category term="tools," /><category term="viewers" /><summary type="html"><![CDATA[Please join us Friday, 04/19/2024 11AM ET, for a talk titled “Practical improvements to image sharing workflows in Minerva”. A free and open-source tool, Minerva, has long been in use to render static single-page websites that share scientific images with collaborators and the public. New priorities have emerged from a growing number of users: embedding sample-specific metadata, generating similar pages for many samples, and exporting all channels with semi-automated contrast settings. New workflows and processes to address these needs emerged from a collaborative effort led by the data management and informatics teams at the LSP.]]></summary></entry><entry><title type="html">25th Meeting “Performant Web-Based Interactive Visualization Tool for Spatially-Resolved Transcriptomics Experiments”</title><link href="/vim-web/2024/03/08/meeting-25.html" rel="alternate" type="text/html" title="25th Meeting “Performant Web-Based Interactive Visualization Tool for Spatially-Resolved Transcriptomics Experiments”" /><published>2024-03-08T00:00:00+00:00</published><updated>2024-10-23T19:13:52+00:00</updated><id>/vim-web/2024/03/08/meeting-25</id><content type="html" xml:base="/vim-web/2024/03/08/meeting-25.html"><![CDATA[<p>Please join us Friday, 03/08/2024 11AM ET, for a talk titled “Samui Browser - Performant Web-Based Interactive Visualization Tool for Spatially-Resolved Transcriptomics Experiments”. 
Samui lets the user rapidly and smoothly visualizes their images anywhere without any need for them to download any software or even the images themselves. Samui achieves this without any use of a backend server, relying only on a static cloud storage. It also supports image annotations, which are exportable in the GeoJSON for fast sharing.</p>

<p>Presenters: Chaichontat Sriworarat (Richard) is a graduate student in neuroscience at the Johns Hopkins School of Medicine under the co-mentorship of Drs. Loyal Goff and Genevieve Stein-O’Brien. He’s currently investigating the relationship between the cell cycle and brain development using single cell and spatial transcriptomics. He also enjoys making tools that addresses pain points that scientists encounter to make research more efficient and reproducible .</p>]]></content><author><name>Chaichontat Sriworarat, graduate student in neuroscience, Johns Hopkins School of Medicine</name></author><category term="visualization," /><category term="tools," /><category term="viewers" /><summary type="html"><![CDATA[Please join us Friday, 03/08/2024 11AM ET, for a talk titled “Samui Browser - Performant Web-Based Interactive Visualization Tool for Spatially-Resolved Transcriptomics Experiments”. Samui lets the user rapidly and smoothly visualizes their images anywhere without any need for them to download any software or even the images themselves. Samui achieves this without any use of a backend server, relying only on a static cloud storage. It also supports image annotations, which are exportable in the GeoJSON for fast sharing.]]></summary></entry><entry><title type="html">24th Meeting “Under the hood of the HTAN DCC”</title><link href="/vim-web/2024/02/09/meeting-24.html" rel="alternate" type="text/html" title="24th Meeting “Under the hood of the HTAN DCC”" /><published>2024-02-09T00:00:00+00:00</published><updated>2024-10-23T19:13:52+00:00</updated><id>/vim-web/2024/02/09/meeting-24</id><content type="html" xml:base="/vim-web/2024/02/09/meeting-24.html"><![CDATA[<p>Please join us Friday, 02/09/2024 11AM ET, for a talk titled “Under the hood of the HTAN DCC”. The Human Tumor Atlas Network Data Coordinating Center provides the tools, resources and expertise to enable HTAN data contributors to annotate and share their multiplexed tissue imaging and advanced sequencing data according to FAIR principles. In this talk, Adam Taylor, Senior Scientist at Sage Bionetworks, will take you under the hood of the HTAN DCC to look at some of its infrastructure and operations; exposing the challenges of curating and sharing thousands of datasets and millions of metadata attributes across ten research programs.</p>

<p>Presenters: Adam Taylor is a Senior Research Scientist at Sage Bionetworks. His research interests are in the application of multimodal mass spectrometry imaging and advanced data analysis approaches to unravel spatial heterogeneity in tumour metabolism.</p>]]></content><author><name>Adam Taylor, Senior Research Scientist, Sage Bionetworks</name></author><category term="platforms," /><category term="management," /><category term="tools" /><summary type="html"><![CDATA[Please join us Friday, 02/09/2024 11AM ET, for a talk titled “Under the hood of the HTAN DCC”. The Human Tumor Atlas Network Data Coordinating Center provides the tools, resources and expertise to enable HTAN data contributors to annotate and share their multiplexed tissue imaging and advanced sequencing data according to FAIR principles. In this talk, Adam Taylor, Senior Scientist at Sage Bionetworks, will take you under the hood of the HTAN DCC to look at some of its infrastructure and operations; exposing the challenges of curating and sharing thousands of datasets and millions of metadata attributes across ten research programs.]]></summary></entry><entry><title type="html">23th Meeting “Residency Octree - A Hybrid Approach for Scalable Web-Based Multi-Volume Rendering”</title><link href="/vim-web/2023/12/08/meeting-23.html" rel="alternate" type="text/html" title="23th Meeting “Residency Octree - A Hybrid Approach for Scalable Web-Based Multi-Volume Rendering”" /><published>2023-12-08T00:00:00+00:00</published><updated>2024-10-23T19:13:52+00:00</updated><id>/vim-web/2023/12/08/meeting-23</id><content type="html" xml:base="/vim-web/2023/12/08/meeting-23.html"><![CDATA[<p>Please join us Friday, 12/08/2023 11AM ET for a talk titled “Residency Octree: A Hybrid Approach for Scalable Web-Based Multi-Volume Rendering”. We present a hybrid multi-volume rendering approach based on a novel Residency Octree that combines the advantages of out-of-core volume rendering using page tables with those of standard octrees. Octree approaches work by performing hierarchical tree traversal. However, in octree volume rendering, tree traversal and the selection of data resolution are intrinsically coupled. This makes fine-grained empty-space skipping costly. Page tables, on the other hand, allow access to any cached brick from any resolution. However, they do not offer a clear and efficient strategy for substituting missing high-resolution data with lower-resolution data. We enable flexible mixed-resolution out-of-core multi-volume rendering by decoupling the cache residency of multi-resolution data from a resolution-independent spatial subdivision determined by the tree. Instead of one-to-one node-to-brick correspondences, each residency octree node is mapped to a set of bricks from different resolution levels. This makes it possible to efficiently and adaptively choose and mix resolutions, adapt sampling rates, and compensate for cache misses. At the same time, residency octrees support fine-grained empty-space skipping, independent of the data subdivision used for caching. Finally, to facilitate collaboration and outreach, and to eliminate local data storage, our implementation is a web-based, pure client-side renderer using WebGPU and WebAssembly. Our method is faster than prior approaches and efficient for many data channels with a flexible and adaptive choice of data resolution.</p>

<p>Presenters: Lukas Herzberger hold a Master in Computer Science from the University of Vienna. He was a visiting researcher in 22/23 at the Laboratory of Pharmacology at Harvard Medical School in collaboration with the Visual Computing Group at Harvard SEAS.</p>

<p><a href="https://vcg.seas.harvard.edu/publications/residency-octree/paper">https://vcg.seas.harvard.edu/publications/residency-octree/paper</a></p>]]></content><author><name>Lukas Herberger, Master Student, University of Vienna, Visiting Research Fellow at LSP, Harvard Medical School</name></author><category term="visualization," /><category term="formats," /><category term="viewers" /><summary type="html"><![CDATA[Please join us Friday, 12/08/2023 11AM ET for a talk titled “Residency Octree: A Hybrid Approach for Scalable Web-Based Multi-Volume Rendering”. We present a hybrid multi-volume rendering approach based on a novel Residency Octree that combines the advantages of out-of-core volume rendering using page tables with those of standard octrees. Octree approaches work by performing hierarchical tree traversal. However, in octree volume rendering, tree traversal and the selection of data resolution are intrinsically coupled. This makes fine-grained empty-space skipping costly. Page tables, on the other hand, allow access to any cached brick from any resolution. However, they do not offer a clear and efficient strategy for substituting missing high-resolution data with lower-resolution data. We enable flexible mixed-resolution out-of-core multi-volume rendering by decoupling the cache residency of multi-resolution data from a resolution-independent spatial subdivision determined by the tree. Instead of one-to-one node-to-brick correspondences, each residency octree node is mapped to a set of bricks from different resolution levels. This makes it possible to efficiently and adaptively choose and mix resolutions, adapt sampling rates, and compensate for cache misses. At the same time, residency octrees support fine-grained empty-space skipping, independent of the data subdivision used for caching. Finally, to facilitate collaboration and outreach, and to eliminate local data storage, our implementation is a web-based, pure client-side renderer using WebGPU and WebAssembly. Our method is faster than prior approaches and efficient for many data channels with a flexible and adaptive choice of data resolution.]]></summary></entry><entry><title type="html">22th Meeting “Towards a thick-tissue 3D atlas for characterizing cell neighborhoods and shape in melanoma with CyCIF”</title><link href="/vim-web/2023/11/17/meeting-22.html" rel="alternate" type="text/html" title="22th Meeting “Towards a thick-tissue 3D atlas for characterizing cell neighborhoods and shape in melanoma with CyCIF”" /><published>2023-11-17T00:00:00+00:00</published><updated>2024-10-23T19:13:52+00:00</updated><id>/vim-web/2023/11/17/meeting-22</id><content type="html" xml:base="/vim-web/2023/11/17/meeting-22.html"><![CDATA[<p>Please join us Friday, 11/17/2023 11AM ET for a talk titled “Towards a thick-tissue 3D atlas for characterizing cell neighborhoods and shape in melanoma with CyCIF”. Microscopy-based tissue imaging is commonly performed at a resolution sufficient to determine cell types but not detect the subtle morphological features associated with cytoskeletal reorganisation, juxtracrine signalling, or membrane trafficking. Here we introduce a 3D imaging approach with high-resolution 54-plex cyclic immunofluorescence (CyCIF) using existing instruments and reagents that is able to characterize a wide variety of organelles and structures at sub-micron scale, cell morphology at the cellular level, while simultaneously quantifying millimetre-scale spatial features.</p>

<p>Presenters: Clarence is the Director of Microscopy and Image Analysis at the Laboratory of Systems Pharmacology (LSP) under Professor Peter Sorger, as well as a research associate at the Image and Data Analysis Core (IDAC) under Dr. Hunter Elliott, and regularly works with the Nikon Imaging Center (NIC) under Dr. Jennifer Waters at Harvard Medical School (HMS). His main interests are in aiding experimental design of imaging assays through collaboration, as well as applying deep learning to 2D, 3D and 4D image analysis problems.</p>]]></content><author><name>Clarence Yapp, Microscopy and Image Analysis at the LSP. Harvard Medical School</name></author><category term="imaging," /><category term="management," /><category term="tools," /><category term="visualization" /><summary type="html"><![CDATA[Please join us Friday, 11/17/2023 11AM ET for a talk titled “Towards a thick-tissue 3D atlas for characterizing cell neighborhoods and shape in melanoma with CyCIF”. Microscopy-based tissue imaging is commonly performed at a resolution sufficient to determine cell types but not detect the subtle morphological features associated with cytoskeletal reorganisation, juxtracrine signalling, or membrane trafficking. Here we introduce a 3D imaging approach with high-resolution 54-plex cyclic immunofluorescence (CyCIF) using existing instruments and reagents that is able to characterize a wide variety of organelles and structures at sub-micron scale, cell morphology at the cellular level, while simultaneously quantifying millimetre-scale spatial features.]]></summary></entry></feed>